Using Theano backend.
Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)
Loading data from
/home/sss1/Desktop/projects/DeepInteractions/data/uniform_len/K562/K562.h5
Shuffling data...
Building model...
Initializing 519 kernels with JASPAR motifs.
Compiling model...
/home/sss1/anaconda2/lib/python2.7/site-packages/keras/models.py:517:
UserWarning: "class_mode" argument is deprecated, please remove it.
  warnings.warn('"class_mode" argument is deprecated, '
Running at most 64 epochs...
/home/sss1/anaconda2/lib/python2.7/site-packages/keras/models.py:580:
UserWarning: The "show_accuracy" argument is deprecated, instead you should
pass the "accuracy" metric to the model at compile time:
`model.compile(optimizer, loss, metrics=["accuracy"])`
  warnings.warn('The "show_accuracy" argument is deprecated, '
Train on 100000 samples, validate on 10000 samples
Epoch 1/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6846 - acc:
0.5672Epoch 00000: val_loss improved from inf to 0.64904, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.6847 - acc:
0.5672 - val_loss: 0.6490 - val_acc: 0.6228
Epoch 2/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6642 - acc:
0.5962Epoch 00001: val_loss improved from 0.64904 to 0.64036, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.6643 - acc:
0.5962 - val_loss: 0.6404 - val_acc: 0.6324
Epoch 3/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6540 - acc:
0.6097Epoch 00002: val_loss improved from 0.64036 to 0.63141, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1059s - loss: 0.6540 - acc:
0.6097 - val_loss: 0.6314 - val_acc: 0.6483
Epoch 4/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6469 - acc:
0.6215Epoch 00003: val_loss improved from 0.63141 to 0.62807, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1057s - loss: 0.6469 - acc:
0.6215 - val_loss: 0.6281 - val_acc: 0.6439
Epoch 5/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6397 - acc:
0.6311Epoch 00004: val_loss improved from 0.62807 to 0.62298, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1058s - loss: 0.6397 - acc:
0.6311 - val_loss: 0.6230 - val_acc: 0.6519
Epoch 6/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6340 - acc:
0.6390Epoch 00005: val_loss improved from 0.62298 to 0.62057, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1059s - loss: 0.6340 - acc:
0.6389 - val_loss: 0.6206 - val_acc: 0.6515
Epoch 7/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6284 - acc:
0.6448Epoch 00006: val_loss improved from 0.62057 to 0.60683, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1059s - loss: 0.6284 - acc:
0.6448 - val_loss: 0.6068 - val_acc: 0.6714
Epoch 8/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6218 - acc:
0.6525Epoch 00007: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.6219 - acc:
0.6525 - val_loss: 0.6091 - val_acc: 0.6650
Epoch 9/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6162 - acc:
0.6583Epoch 00008: val_loss improved from 0.60683 to 0.59800, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1055s - loss: 0.6162 - acc:
0.6581 - val_loss: 0.5980 - val_acc: 0.6766
Epoch 10/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6104 - acc:
0.6626Epoch 00009: val_loss did not improve
100000/100000 [==============================] - 1052s - loss: 0.6105 - acc:
0.6626 - val_loss: 0.6074 - val_acc: 0.6591
Epoch 11/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6054 - acc:
0.6709Epoch 00010: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.6055 - acc:
0.6708 - val_loss: 0.6003 - val_acc: 0.6663
Epoch 12/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.6007 - acc:
0.6756Epoch 00011: val_loss improved from 0.59800 to 0.59247, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1059s - loss: 0.6008 - acc:
0.6755 - val_loss: 0.5925 - val_acc: 0.6761
Epoch 13/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5960 - acc:
0.6775Epoch 00012: val_loss improved from 0.59247 to 0.59140, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5960 - acc:
0.6775 - val_loss: 0.5914 - val_acc: 0.6729
Epoch 14/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5897 - acc:
0.6839Epoch 00013: val_loss improved from 0.59140 to 0.56749, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1059s - loss: 0.5897 - acc:
0.6839 - val_loss: 0.5675 - val_acc: 0.7049
Epoch 15/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5870 - acc:
0.6867Epoch 00014: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5870 - acc:
0.6867 - val_loss: 0.5899 - val_acc: 0.6772
Epoch 16/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5828 - acc:
0.6914Epoch 00015: val_loss improved from 0.56749 to 0.55071, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5829 - acc:
0.6913 - val_loss: 0.5507 - val_acc: 0.7230
Epoch 17/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5776 - acc:
0.6966Epoch 00016: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5776 - acc:
0.6965 - val_loss: 0.5833 - val_acc: 0.6843
Epoch 18/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5737 - acc:
0.6978Epoch 00017: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5737 - acc:
0.6977 - val_loss: 0.5570 - val_acc: 0.7111
Epoch 19/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5690 - acc:
0.7039Epoch 00018: val_loss improved from 0.55071 to 0.53956, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5690 - acc:
0.7038 - val_loss: 0.5396 - val_acc: 0.7309
Epoch 20/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5674 - acc:
0.7047Epoch 00019: val_loss improved from 0.53956 to 0.53648, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5673 - acc:
0.7047 - val_loss: 0.5365 - val_acc: 0.7326
Epoch 21/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5631 - acc:
0.7096Epoch 00020: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5631 - acc:
0.7096 - val_loss: 0.5488 - val_acc: 0.7195
Epoch 22/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5596 - acc:
0.7115Epoch 00021: val_loss improved from 0.53648 to 0.52605, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5595 - acc:
0.7115 - val_loss: 0.5260 - val_acc: 0.7455
Epoch 23/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5572 - acc:
0.7125Epoch 00022: val_loss improved from 0.52605 to 0.51542, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5572 - acc:
0.7124 - val_loss: 0.5154 - val_acc: 0.7506
Epoch 24/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5525 - acc:
0.7177Epoch 00023: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5524 - acc:
0.7178 - val_loss: 0.5250 - val_acc: 0.7415
Epoch 25/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5492 - acc:
0.7189Epoch 00024: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5492 - acc:
0.7189 - val_loss: 0.5334 - val_acc: 0.7307
Epoch 26/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5478 - acc:
0.7204Epoch 00025: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5478 - acc:
0.7205 - val_loss: 0.5230 - val_acc: 0.7405
Epoch 27/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5433 - acc:
0.7257Epoch 00026: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5432 - acc:
0.7257 - val_loss: 0.5371 - val_acc: 0.7264
Epoch 28/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5390 - acc:
0.7284Epoch 00027: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5390 - acc:
0.7284 - val_loss: 0.5664 - val_acc: 0.7021
Epoch 29/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5375 - acc:
0.7291Epoch 00028: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5375 - acc:
0.7291 - val_loss: 0.5400 - val_acc: 0.7242
Epoch 30/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5351 - acc:
0.7303Epoch 00029: val_loss improved from 0.51542 to 0.49297, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5350 - acc:
0.7304 - val_loss: 0.4930 - val_acc: 0.7690
Epoch 31/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5323 - acc:
0.7331Epoch 00030: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5324 - acc:
0.7331 - val_loss: 0.4981 - val_acc: 0.7660
Epoch 32/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5294 - acc:
0.7363Epoch 00031: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5294 - acc:
0.7363 - val_loss: 0.5147 - val_acc: 0.7475
Epoch 33/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5276 - acc:
0.7368Epoch 00032: val_loss improved from 0.49297 to 0.49167, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5275 - acc:
0.7369 - val_loss: 0.4917 - val_acc: 0.7694
Epoch 34/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5268 - acc:
0.7376Epoch 00033: val_loss improved from 0.49167 to 0.49086, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.5267 - acc:
0.7376 - val_loss: 0.4909 - val_acc: 0.7679
Epoch 35/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5214 - acc:
0.7408Epoch 00034: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5214 - acc:
0.7408 - val_loss: 0.4965 - val_acc: 0.7647
Epoch 36/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5193 - acc:
0.7439Epoch 00035: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5193 - acc:
0.7439 - val_loss: 0.4982 - val_acc: 0.7618
Epoch 37/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5174 - acc:
0.7454Epoch 00036: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5174 - acc:
0.7454 - val_loss: 0.5222 - val_acc: 0.7382
Epoch 38/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5145 - acc:
0.7457Epoch 00037: val_loss did not improve
100000/100000 [==============================] - 1057s - loss: 0.5145 - acc:
0.7457 - val_loss: 0.4935 - val_acc: 0.7677
Epoch 39/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5118 - acc:
0.7491Epoch 00038: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5118 - acc:
0.7491 - val_loss: 0.5008 - val_acc: 0.7554
Epoch 40/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5099 - acc:
0.7494Epoch 00039: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.5098 - acc:
0.7494 - val_loss: 0.4948 - val_acc: 0.7610
Epoch 41/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5082 - acc:
0.7510Epoch 00040: val_loss improved from 0.49086 to 0.48088, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.5081 - acc:
0.7510 - val_loss: 0.4809 - val_acc: 0.7752
Epoch 42/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5070 - acc:
0.7518Epoch 00041: val_loss improved from 0.48088 to 0.47130, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.5070 - acc:
0.7518 - val_loss: 0.4713 - val_acc: 0.7814
Epoch 43/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5038 - acc:
0.7541Epoch 00042: val_loss did not improve
100000/100000 [==============================] - 1059s - loss: 0.5038 - acc:
0.7542 - val_loss: 0.4772 - val_acc: 0.7768
Epoch 44/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.5027 - acc:
0.7562Epoch 00043: val_loss improved from 0.47130 to 0.46449, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.5027 - acc:
0.7562 - val_loss: 0.4645 - val_acc: 0.7865
Epoch 45/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4980 - acc:
0.7591Epoch 00044: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4980 - acc:
0.7591 - val_loss: 0.4771 - val_acc: 0.7765
Epoch 46/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4968 - acc:
0.7586Epoch 00045: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4968 - acc:
0.7586 - val_loss: 0.4648 - val_acc: 0.7854
Epoch 47/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4966 - acc:
0.7588Epoch 00046: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4966 - acc:
0.7588 - val_loss: 0.4808 - val_acc: 0.7736
Epoch 48/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4936 - acc:
0.7602Epoch 00047: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4936 - acc:
0.7601 - val_loss: 0.5096 - val_acc: 0.7467
Epoch 49/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4925 - acc:
0.7632Epoch 00048: val_loss improved from 0.46449 to 0.45975, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.4925 - acc:
0.7632 - val_loss: 0.4598 - val_acc: 0.7888
Epoch 50/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4883 - acc:
0.7649Epoch 00049: val_loss improved from 0.45975 to 0.45893, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.4883 - acc:
0.7649 - val_loss: 0.4589 - val_acc: 0.7883
Epoch 51/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4884 - acc:
0.7639Epoch 00050: val_loss improved from 0.45893 to 0.45056, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.4883 - acc:
0.7639 - val_loss: 0.4506 - val_acc: 0.7944
Epoch 52/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4850 - acc:
0.7674Epoch 00051: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4850 - acc:
0.7674 - val_loss: 0.4600 - val_acc: 0.7858
Epoch 53/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4835 - acc:
0.7686Epoch 00052: val_loss improved from 0.45056 to 0.44692, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1061s - loss: 0.4835 - acc:
0.7686 - val_loss: 0.4469 - val_acc: 0.7984
Epoch 54/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4824 - acc:
0.7695Epoch 00053: val_loss improved from 0.44692 to 0.44211, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1060s - loss: 0.4825 - acc:
0.7695 - val_loss: 0.4421 - val_acc: 0.8026
Epoch 55/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4780 - acc:
0.7721Epoch 00054: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4779 - acc:
0.7721 - val_loss: 0.4469 - val_acc: 0.8004
Epoch 56/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4784 - acc:
0.7716Epoch 00055: val_loss did not improve
100000/100000 [==============================] - 1060s - loss: 0.4784 - acc:
0.7716 - val_loss: 0.4548 - val_acc: 0.7891
Epoch 57/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4775 - acc:
0.7734Epoch 00056: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4775 - acc:
0.7734 - val_loss: 0.4706 - val_acc: 0.7768
Epoch 58/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4752 - acc:
0.7742Epoch 00057: val_loss did not improve
100000/100000 [==============================] - 1058s - loss: 0.4751 - acc:
0.7743 - val_loss: 0.4476 - val_acc: 0.7942
Epoch 59/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4717 - acc:
0.7770Epoch 00058: val_loss did not improve
100000/100000 [==============================] - 1059s - loss: 0.4718 - acc:
0.7769 - val_loss: 0.4424 - val_acc: 0.7994
Epoch 60/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4702 - acc:
0.7777Epoch 00059: val_loss did not improve
100000/100000 [==============================] - 1061s - loss: 0.4703 - acc:
0.7777 - val_loss: 0.4459 - val_acc: 0.7954
Epoch 61/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4694 - acc:
0.7776Epoch 00060: val_loss improved from 0.44211 to 0.43240, saving model to
/home/sss1/Desktop/projects/DeepInteractions/weights/myDanQ-JASPAR_bestmodel-2016-08-22-17:55:13.hdf5
100000/100000 [==============================] - 1074s - loss: 0.4694 - acc:
0.7776 - val_loss: 0.4324 - val_acc: 0.8060
Epoch 62/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4671 - acc:
0.7783Epoch 00061: val_loss did not improve
100000/100000 [==============================] - 1074s - loss: 0.4672 - acc:
0.7783 - val_loss: 0.4382 - val_acc: 0.8012
Epoch 63/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4637 - acc:
0.7816Epoch 00062: val_loss did not improve
100000/100000 [==============================] - 1070s - loss: 0.4638 - acc:
0.7816 - val_loss: 0.4385 - val_acc: 0.8003
Epoch 64/64
 99900/100000 [============================>.] - ETA: 1s - loss: 0.4644 - acc:
0.7798Epoch 00063: val_loss did not improve
100000/100000 [==============================] - 1070s - loss: 0.4644 - acc:
0.7798 - val_loss: 0.4534 - val_acc: 0.7905
